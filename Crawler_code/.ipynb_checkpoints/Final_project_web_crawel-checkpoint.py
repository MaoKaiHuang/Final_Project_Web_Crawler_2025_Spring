{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7a38f860-9f76-4703-b63f-0722356c5a0f",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98a730c0-2e91-4383-b259-80937925e5c9",
   "metadata": {},
   "source": [
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "chrome_driver_path = \"C:\\\\Program Files\\\\Google\\\\Chrome\\\\Application\\\\chromedriver.exe\"\n",
    "service = Service(executable_path=chrome_driver_path)\n",
    "\n",
    "browser = webdriver.Chrome(service=service)\n",
    "url =\n",
    "\n",
    "browser.set_window_size(1024, 960)\n",
    "browser.get(url)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a371b4a1-699c-4494-89e0-5745116f6fd6",
   "metadata": {},
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 儲存資料夾路徑\n",
    "save_path = r\"C:\\Users\\Mao-k\\網頁爬蟲\\Final_Project\\Web_crawel_Data\\LetterBox_movie\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# 設定 Selenium\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "try:\n",
    "    # Step 1：搜尋電影\n",
    "    search_query = \"悲情城市\"\n",
    "    search_url = f\"https://letterboxd.com/search/{search_query}/\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Step 2：點擊第一筆結果\n",
    "    movie_link = driver.find_element(By.XPATH, '//ul[@class=\"results\"]/li//a[contains(@href, \"/film/\")]')\n",
    "    movie_link.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Step 3：解析頁面\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Step 4：擷取基本資料\n",
    "    title = soup.find(\"h1\", class_=\"headline-1\").text.strip() if soup.find(\"h1\", class_=\"headline-1\") else \"N/A\"\n",
    "\n",
    "    year_tag = soup.select_one(\"div.metablock div.releaseyear a\")\n",
    "    year = year_tag.text.strip() if year_tag else \"N/A\"\n",
    "\n",
    "    description_tag = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    description = description_tag[\"content\"] if description_tag else \"N/A\"\n",
    "\n",
    "    poster_a_tag = soup.find(\"a\", attrs={\"data-js-trigger\": \"postermodal\"})\n",
    "    poster_url = poster_a_tag[\"href\"] if poster_a_tag else \"N/A\"\n",
    "\n",
    "    # Step 5：平均分數與總評價數\n",
    "    average_score = \"N/A\"\n",
    "    total_ratings = \"N/A\"\n",
    "    rating_block = soup.select_one('section.ratings-histogram-chart')\n",
    "    if rating_block:\n",
    "        avg_tag = rating_block.select_one('span.average-rating a')\n",
    "        if avg_tag:\n",
    "            title_text = avg_tag.get('data-original-title', '')\n",
    "            match = re.search(r'([\\d.]+).*?based on ([\\d,]+)', title_text)\n",
    "            if match:\n",
    "                average_score = match.group(1)\n",
    "                total_ratings = match.group(2).replace(',', '')\n",
    "\n",
    "    # Step 6：擷取各星等的評價數量（★ 修正處）\n",
    "    star_ratings = {\n",
    "        '0.5': 0, '1': 0, '1.5': 0, '2': 0, '2.5': 0,\n",
    "        '3': 0, '3.5': 0, '4': 0, '4.5': 0, '5': 0\n",
    "    }\n",
    "\n",
    "    rating_map = {\n",
    "        'half-★': '0.5', '★': '1', '★½': '1.5', '★★': '2', '★★½': '2.5',\n",
    "        '★★★': '3', '★★★½': '3.5', '★★★★': '4', '★★★★½': '4.5', '★★★★★': '5'\n",
    "    }\n",
    "\n",
    "    for li in soup.select('li.rating-histogram-bar'):\n",
    "        a_tag = li.find('a')\n",
    "        if a_tag:\n",
    "            tooltip = a_tag.get(\"data-original-title\", \"\")\n",
    "            match = re.search(r'([\\d,]+)\\s+([\\S]+) ratings', tooltip)\n",
    "            if match:\n",
    "                count = int(match.group(1).replace(\",\", \"\"))\n",
    "                stars_text = match.group(2)\n",
    "                rating_value = rating_map.get(stars_text)\n",
    "                if rating_value:\n",
    "                    star_ratings[rating_value] = count\n",
    "\n",
    "    # Step 7：建立 DataFrame 並匯出 CSV\n",
    "    movie_data = [{\n",
    "        \"電影標題\": title,\n",
    "        \"上映年份\": year,\n",
    "        \"電影描述\": description,\n",
    "        \"海報圖片\": poster_url,\n",
    "        \"平均評分\": average_score,\n",
    "        \"評分總數\": total_ratings,\n",
    "        \"0.5星\": star_ratings['0.5'],\n",
    "        \"1星\": star_ratings['1'],\n",
    "        \"1.5星\": star_ratings['1.5'],\n",
    "        \"2星\": star_ratings['2'],\n",
    "        \"2.5星\": star_ratings['2.5'],\n",
    "        \"3星\": star_ratings['3'],\n",
    "        \"3.5星\": star_ratings['3.5'],\n",
    "        \"4星\": star_ratings['4'],\n",
    "        \"4.5星\": star_ratings['4.5'],\n",
    "        \"5星\": star_ratings['5']\n",
    "    }]\n",
    "\n",
    "    df = pd.DataFrame(movie_data)\n",
    "    csv_path = os.path.join(save_path, f\"{search_query}_movie_info.csv\")\n",
    "    df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ 成功儲存：{csv_path}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c60e39ec-3dd0-420d-9428-c5f9e40d1960",
   "metadata": {},
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def convert_rating_to_number(rating_str):\n",
    "    if not rating_str:\n",
    "        return \"\"\n",
    "    stars = rating_str.count(\"★\")\n",
    "    half = \"½\" in rating_str\n",
    "    return stars + 0.5 if half else stars\n",
    "\n",
    "def get_letterboxd_reviews(movie_url, search_term):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--window-size=1200,900\")\n",
    "    # chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    reviews_url = movie_url.rstrip(\"/\") + \"/reviews/by/activity/\"\n",
    "\n",
    "    try:\n",
    "        print(f\"📄 前往評論頁面：{reviews_url}\")\n",
    "        driver.get(reviews_url)\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "\n",
    "        print(\"⌛ 等待評論清單載入...\")\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"viewing-list\")))\n",
    "\n",
    "        review_list = driver.find_elements(By.CSS_SELECTOR, \".viewing-list .listitem article\")\n",
    "        print(f\"📝 找到 {len(review_list)} 筆評論\")\n",
    "\n",
    "        output_folder = r\"C:\\Users\\Mao-k\\網頁爬蟲\\Final_Project\\Web_crawel_Data\\LetterBox_movie\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        filename = f\"{search_term}_reviews.csv\"\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        with open(output_path, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Reviewer\", \"Rating\", \"Date\", \"Content\", \"Likes\"])\n",
    "\n",
    "            for review in review_list:\n",
    "                try:\n",
    "                    reviewer = review.find_element(By.CSS_SELECTOR, \".displayname\").text\n",
    "                except:\n",
    "                    reviewer = \"無名稱\"\n",
    "\n",
    "                try:\n",
    "                    rating_text = review.find_element(By.CSS_SELECTOR, \"span.rating\").text.strip()\n",
    "                    rating = convert_rating_to_number(rating_text)\n",
    "                except:\n",
    "                    rating = \"\"\n",
    "\n",
    "                try:\n",
    "                    date = review.find_element(By.CSS_SELECTOR, \"time.timestamp\").get_attribute(\"datetime\")\n",
    "                except:\n",
    "                    date = \"\"\n",
    "\n",
    "                try:\n",
    "                    content = review.find_element(By.CSS_SELECTOR, \"div.js-review-body\").text.strip()\n",
    "                except:\n",
    "                    content = \"\"\n",
    "\n",
    "                try:\n",
    "                    likes_text = review.find_element(By.CSS_SELECTOR, \"span._count_8kxo2_22\").text\n",
    "                    likes = int(re.search(r\"\\d+\", likes_text.replace(\",\", \"\")).group())\n",
    "                except:\n",
    "                    likes = 0\n",
    "\n",
    "                print(f\"{reviewer} | {rating} | {date} | 👍 {likes}\")\n",
    "                writer.writerow([reviewer, rating, date, content, likes])\n",
    "\n",
    "        print(f\"✅ 資料已儲存至：{output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 發生錯誤：{repr(e)}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "# ✅ 使用範例\n",
    "get_letterboxd_reviews(\n",
    "    movie_url=\"https://letterboxd.com/film/a-city-of-sadness/\",\n",
    "    search_term=\"a city of sadness\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338c3233-7f0e-4555-a9ad-70e011881670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"C:/Users/Mao-k/網頁爬蟲/Final_Project_Web_Crawler_2025_Spring/site\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d9821ef-0604-411b-bd98-99d81145a378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功儲存：C:\\Users\\Mao-k\\網頁爬蟲\\Final_Project_Web_Crawler_2025_Spring\\Web_crawel_Data\\LetterBox_movie\\玩命關頭4_movie_info.csv\n",
      "📄 前往評論頁面：https://letterboxd.com/film/fast-furious/reviews/by/activity/\n",
      "⌛ 等待評論清單載入...\n",
      "📝 找到 12 筆評論\n",
      "Willow Maclay | 3 | 2015-04-05 | 👍 2125\n",
      "Josh Larsen | 3.5 | 2015-03-28 | 👍 1933\n",
      "Josh Lewis | 2 | 2015-03-25 | 👍 1679\n",
      "Andy Young | 3.5 | 2021-06-19 | 👍 1186\n",
      "Lucy | 2 | 2021-06-22 | 👍 970\n",
      "Matt Singer | 3.5 | 2021-06-24 | 👍 838\n",
      "Bryan Espitia | 3.5 | 2021-05-21 | 👍 651\n",
      "Bryan Espitia | 3.5 | 2023-05-06 | 👍 642\n",
      "demi adejuyigbe |  | 2021-06-19 | 👍 499\n",
      "Wood | 3 | 2015-04-08 | 👍 424\n",
      "Framesofnick | 2 | 2020-07-15 | 👍 349\n",
      "Leah 🥀 | 3 | 2022-03-13 | 👍 330\n",
      "✅ 評論資料已儲存至：C:\\Users\\Mao-k\\網頁爬蟲\\Final_Project_Web_Crawler_2025_Spring\\Web_crawel_Data\\LetterBox_movie\\玩命關頭4_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# 儲存資料夾路徑\n",
    "base_path = r\"C:\\Users\\Mao-k\\網頁爬蟲\\Final_Project_Web_Crawler_2025_Spring\"\n",
    "save_path = r\"C:\\Users\\Mao-k\\網頁爬蟲\\Final_Project_Web_Crawler_2025_Spring\\Web_crawel_Data\\LetterBox_movie\"\n",
    "data_folder = r\"C:\\Users\\Mao-k\\網頁爬蟲\\Final_Project_Web_Crawler_2025_Spring\\data\"\n",
    "site = os.path.join(base_path, \"Crawler_code\", \"site\")\n",
    "os.makedirs(site, exist_ok=True)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# 設定 Selenium\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--window-size=1200,900\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "search_query = \"玩命關頭4\"\n",
    "safe_query = search_query.strip().replace(\" \", \"_\")\n",
    "\n",
    "try:\n",
    "    # Step 1：搜尋電影\n",
    "    search_url = f\"https://letterboxd.com/search/{search_query}/\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Step 2：點擊第一筆結果\n",
    "    movie_link = driver.find_element(By.XPATH, '//ul[@class=\"results\"]/li//a[contains(@href, \"/film/\")]')\n",
    "    movie_link.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Step 3：解析頁面\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Step 4：擷取基本資料\n",
    "    title = soup.find(\"h1\", class_=\"headline-1\").text.strip() if soup.find(\"h1\", class_=\"headline-1\") else \"N/A\"\n",
    "\n",
    "    year_tag = soup.select_one(\"div.metablock div.releaseyear a\")\n",
    "    year = year_tag.text.strip() if year_tag else \"N/A\"\n",
    "\n",
    "    description_tag = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    description = description_tag[\"content\"] if description_tag else \"N/A\"\n",
    "\n",
    "    poster_a_tag = soup.find(\"a\", attrs={\"data-js-trigger\": \"postermodal\"})\n",
    "    poster_url = poster_a_tag[\"href\"] if poster_a_tag else \"N/A\"\n",
    "\n",
    "    # Step 5：平均分數與總評價數\n",
    "    average_score = \"N/A\"\n",
    "    total_ratings = \"N/A\"\n",
    "    rating_block = soup.select_one('section.ratings-histogram-chart')\n",
    "    if rating_block:\n",
    "        avg_tag = rating_block.select_one('span.average-rating a')\n",
    "        if avg_tag:\n",
    "            title_text = avg_tag.get('data-original-title', '')\n",
    "            match = re.search(r'([\\d.]+).*?based on ([\\d,]+)', title_text)\n",
    "            if match:\n",
    "                average_score = match.group(1)\n",
    "                total_ratings = match.group(2).replace(',', '')\n",
    "\n",
    "    # Step 6：擷取各星等的評價數量\n",
    "    star_ratings = {\n",
    "        '0.5': 0, '1': 0, '1.5': 0, '2': 0, '2.5': 0,\n",
    "        '3': 0, '3.5': 0, '4': 0, '4.5': 0, '5': 0\n",
    "    }\n",
    "\n",
    "    rating_map = {\n",
    "        'half-★': '0.5', '★': '1', '★½': '1.5', '★★': '2', '★★½': '2.5',\n",
    "        '★★★': '3', '★★★½': '3.5', '★★★★': '4', '★★★★½': '4.5', '★★★★★': '5'\n",
    "    }\n",
    "\n",
    "    for li in soup.select('li.rating-histogram-bar'):\n",
    "        a_tag = li.find('a')\n",
    "        if a_tag:\n",
    "            tooltip = a_tag.get(\"data-original-title\", \"\")\n",
    "            match = re.search(r'([\\d,]+)\\s+([\\S]+) ratings', tooltip)\n",
    "            if match:\n",
    "                count = int(match.group(1).replace(\",\", \"\"))\n",
    "                stars_text = match.group(2)\n",
    "                rating_value = rating_map.get(stars_text)\n",
    "                if rating_value:\n",
    "                    star_ratings[rating_value] = count\n",
    "\n",
    "    # Step 7：建立 DataFrame 並匯出 CSV\n",
    "    movie_data = [{\n",
    "        \"電影標題\": title,\n",
    "        \"上映年份\": year,\n",
    "        \"電影描述\": description,\n",
    "        \"海報圖片\": poster_url,\n",
    "        \"平均評分\": average_score,\n",
    "        \"評分總數\": total_ratings,\n",
    "        \"0.5星\": star_ratings['0.5'],\n",
    "        \"1星\": star_ratings['1'],\n",
    "        \"1.5星\": star_ratings['1.5'],\n",
    "        \"2星\": star_ratings['2'],\n",
    "        \"2.5星\": star_ratings['2.5'],\n",
    "        \"3星\": star_ratings['3'],\n",
    "        \"3.5星\": star_ratings['3.5'],\n",
    "        \"4星\": star_ratings['4'],\n",
    "        \"4.5星\": star_ratings['4.5'],\n",
    "        \"5星\": star_ratings['5']\n",
    "    }]\n",
    "\n",
    "    df = pd.DataFrame(movie_data)\n",
    "    csv_path = os.path.join(save_path, f\"{safe_query}_movie_info.csv\")\n",
    "    df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ 成功儲存：{csv_path}\")\n",
    "\n",
    "    # Step 8：擷取評論資料\n",
    "    reviews_url = driver.current_url.rstrip(\"/\") + \"/reviews/by/activity/\"\n",
    "    print(f\"📄 前往評論頁面：{reviews_url}\")\n",
    "    driver.get(reviews_url)\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "\n",
    "    print(\"⌛ 等待評論清單載入...\")\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"viewing-list\")))\n",
    "\n",
    "    review_list = driver.find_elements(By.CSS_SELECTOR, \".viewing-list .listitem article\")\n",
    "    print(f\"📝 找到 {len(review_list)} 筆評論\")\n",
    "\n",
    "    filename = f\"{safe_query}_reviews.csv\"\n",
    "    output_path = os.path.join(save_path, filename)\n",
    "\n",
    "    def convert_rating_to_number(rating_str):\n",
    "        if not rating_str:\n",
    "            return \"\"\n",
    "        stars = rating_str.count(\"★\")\n",
    "        half = \"½\" in rating_str\n",
    "        return stars + 0.5 if half else stars\n",
    "\n",
    "    with open(output_path, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Reviewer\", \"Rating\", \"Date\", \"Content\", \"Likes\"])\n",
    "\n",
    "        for review in review_list:\n",
    "            try:\n",
    "                reviewer = review.find_element(By.CSS_SELECTOR, \".displayname\").text\n",
    "            except:\n",
    "                reviewer = \"無名稱\"\n",
    "\n",
    "            try:\n",
    "                rating_text = review.find_element(By.CSS_SELECTOR, \"span.rating\").text.strip()\n",
    "                rating = convert_rating_to_number(rating_text)\n",
    "            except:\n",
    "                rating = \"\"\n",
    "\n",
    "            try:\n",
    "                date = review.find_element(By.CSS_SELECTOR, \"time.timestamp\").get_attribute(\"datetime\")\n",
    "            except:\n",
    "                date = \"\"\n",
    "\n",
    "            try:\n",
    "                content = review.find_element(By.CSS_SELECTOR, \"div.js-review-body\").text.strip()\n",
    "            except:\n",
    "                content = \"\"\n",
    "\n",
    "            try:\n",
    "                likes_text = review.find_element(By.CSS_SELECTOR, \"span._count_8kxo2_22\").text\n",
    "                likes = int(re.search(r\"\\d+\", likes_text.replace(\",\", \"\")).group())\n",
    "            except:\n",
    "                likes = 0\n",
    "\n",
    "            print(f\"{reviewer} | {rating} | {date} | 👍 {likes}\")\n",
    "            writer.writerow([reviewer, rating, date, content, likes])\n",
    "\n",
    "    print(f\"✅ 評論資料已儲存至：{output_path}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "def convert_csv_to_json(search_query):\n",
    "    safe_query = search_query.strip().replace(\" \", \"_\")\n",
    "    \n",
    "    movie_csv = os.path.join(save_path, f\"{safe_query}_movie_info.csv\")\n",
    "    reviews_csv = os.path.join(save_path, f\"{safe_query}_reviews.csv\")\n",
    "    movie_json = os.path.join(site, f\"{safe_query}_movie_info.json\")\n",
    "    reviews_json = os.path.join(site, f\"{safe_query}_reviews.json\")\n",
    "\n",
    "    os.makedirs(site, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        df_movie = pd.read_csv(movie_csv, encoding='utf-8-sig')\n",
    "        df_reviews = pd.read_csv(reviews_csv, encoding='utf-8-sig')\n",
    "\n",
    "        df_movie.to_json(movie_json, orient='records', force_ascii=False)\n",
    "        df_reviews.to_json(reviews_json, orient='records', force_ascii=False)\n",
    "\n",
    "        print(f\"✅ 已轉換 JSON 並儲存至：\\n{movie_json}\\n{reviews_json}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ 找不到檔案：{e.filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f7dfc-955e-4298-846e-997fe0421251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "339ed383-254a-4f8f-8dbb-4b990a726622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd12ed-a5f0-4860-b901-d2cc789f0214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
